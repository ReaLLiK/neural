{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "61499064",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential, model_from_json\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import LSTM, SpatialDropout1D\n",
    "from keras.datasets import imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "decefba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "max_features = 8000\n",
    "maxlen = 100\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=maxlen)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3ab10033",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 32))\n",
    "model.add(SpatialDropout1D(0.2))\n",
    "model.add(LSTM(75, dropout=0.2, recurrent_dropout=0.2)) \n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "cdac5849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 71ms/step - accuracy: 0.7607 - loss: 0.4941 - val_accuracy: 0.8312 - val_loss: 0.3872\n",
      "Epoch 2/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 71ms/step - accuracy: 0.8494 - loss: 0.3548 - val_accuracy: 0.8449 - val_loss: 0.3667\n",
      "Epoch 3/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 79ms/step - accuracy: 0.8728 - loss: 0.3112 - val_accuracy: 0.8436 - val_loss: 0.3669\n",
      "Epoch 4/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 81ms/step - accuracy: 0.8924 - loss: 0.2679 - val_accuracy: 0.8447 - val_loss: 0.3875\n",
      "Epoch 5/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 82ms/step - accuracy: 0.9068 - loss: 0.2338 - val_accuracy: 0.8446 - val_loss: 0.3789\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.8446 - loss: 0.3789\n",
      "Точность на тестовых данных: 84.46%\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=16, epochs=5,validation_data=(X_test, y_test), verbose=1)\n",
    "scores = model.evaluate(X_test, y_test, batch_size=16)\n",
    "print(\"Точность на тестовых данных: %.2f%%\" % (scores[1] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2ac8aeb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "json_file = open(\"LSTM.json\", \"w\")\n",
    "json_file.write(model_json)\n",
    "json_file.close()\n",
    "model.save_weights(\"LSTM.weights.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "33fec879",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file = open(\"LSTM.json\", \"r\")\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "loaded_model.load_weights(\"LSTM.weights.h5\")\n",
    "loaded_model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5088a85c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it could get any worse and it does the storyline is so predictable it seems written by a high school <UNK> class the sets are pathetic but <UNK> better than the <UNK> and the acting is wooden br br the <UNK> <UNK> seems to have been stolen from the props <UNK> of <UNK> <UNK> there didn't seem to be a single original idea in the whole movie br br i found this movie to be so bad that i laughed most of the way through br br <UNK> <UNK> should hang his head in shame he obviously needed the money\n",
      "<UNK> class the sets are pathetic but <UNK> better than the <UNK> and the acting is wooden br br the <UNK> <UNK> seems to have been stolen from the props <UNK> of <UNK> <UNK> there didn't seem to be a single original idea in the whole movie br br i found this movie to be so bad that i laughed most of the way through br br <UNK> <UNK> should hang his head in shame he obviously needed the money\n"
     ]
    }
   ],
   "source": [
    "NUM_WORDS = 5000\n",
    "INDEX_FROM = 3\n",
    "word_to_id = imdb.get_word_index()\n",
    "word_to_id = {k:(v+INDEX_FROM) for k,v in word_to_id.items()}\n",
    "word_to_id[\"<PAD>\"] = 0\n",
    "word_to_id[\"<START>\"] = 1\n",
    "word_to_id[\"<UNK>\"] = 2\n",
    "id_to_word = {value:key for key, value in word_to_id.items()}\n",
    "review_id = 20\n",
    "print(' '.join(id_to_word[num] for num in X_train[review_id] ))\n",
    "print(' '.join(id_to_word[num] for num in sequence.pad_sequences(X_train, maxlen=80)[review_id] ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "febe71f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tester = \"A masterclass in film making, is The Godfather a contender for the best film of all time?I'd argue the case that it is, this is the ultimate gangster movie. Before you panic at the thought of a film being almost three hours long, you needn't, you won't even notice the time, it flies by. Production values are incredible, it looks sublime the whole way through, it's so well produced, at roughly fifty years old it puts many new films to shame. Brandon, Pacino and Castellano, just a few of the Incredible performances, I could add a whole lot more. If you're considering buying a hard copy, I would recommend it on blu ray, it is sharper than the dvd, there is a difference. This film has had a huge influence down the years, it is still, and will forever be, one of the greatest, 10/10.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a5aca788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "Результат: +\n",
      "Оценка: 0.8111\n"
     ]
    }
   ],
   "source": [
    "def encode_review(text):\n",
    "    words = text.lower().replace('.', '').replace(',', '').replace(\"'\", \"\").split()\n",
    "    encoded = [1]\n",
    "    for w in words:\n",
    "        idx = word_to_id.get(w, 2)\n",
    "        if idx >= max_features:\n",
    "            idx = 2\n",
    "        encoded.append(idx)\n",
    "    return encoded\n",
    "encoded_review = encode_review(tester)\n",
    "padded_review = sequence.pad_sequences([encoded_review], maxlen=maxlen)\n",
    "prediction = loaded_model.predict(padded_review)\n",
    "sentiment = \"+\" if prediction[0][0] > 0.5 else \"-\"\n",
    "print(f\"Результат: {sentiment}\")\n",
    "print(f\"Оценка: {prediction[0][0]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "bde760ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "tester2 = \"I'm not surprised that so many people fell for this one. When I was watching this movie, a couple viewers next to me sobbed whenever you're 'supposed' to sob -- or at least feel 'touched'. Like when Hunting said he didn't love the girl. Like when Robin Williams' character (sorry I forgot his role's name) was telling Hunting repeatedly 'It's not your fault' (oh Lord, just thinking of that scene gives me the goosebumps). I couldn't have cared less for what would happen to the characters. Many people sob for Hollywood manufactured characters they can't even relate to (think Titanic; Yuck!)... but it really only made me cringe and want to get out of the theatre. I guess I simply refuse to be psychically and emotionally manipulated by all this. Folks it's not me who's being condescending ... those characters are, and for no good reason because they're unreal. Worse yet, nothing is new or surprising. Even Robin Williams' character is all cliched. I gave it 1 out of 10. It's probably not that bad; it's just quite mediocre... but so many people went to the other extreme and gave it a 10 so I figured a single balancing vote won't hurt.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ba23cb21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "Результат: -\n",
      "Оценка: 0.0105\n"
     ]
    }
   ],
   "source": [
    "encoded_review2 = encode_review(tester2)\n",
    "padded_review2 = sequence.pad_sequences([encoded_review2], maxlen=maxlen)\n",
    "prediction2 = loaded_model.predict(padded_review2)\n",
    "sentiment2 = \"+\" if prediction2[0][0] > 0.5 else \"-\"\n",
    "print(f\"Результат: {sentiment2}\")\n",
    "print(f\"Оценка: {prediction2[0][0]:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
